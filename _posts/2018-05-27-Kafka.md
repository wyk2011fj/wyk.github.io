---
layout:         post
title:          kafka
subtitle:       
card-image:     https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1527439545812&di=dca1c7b4d7a7b9dbdfcd2f794e09693f&imgtype=0&src=http%3A%2F%2Fwww.liuhaihua.cn%2Fwp-content%2Fuploads%2F2016%2F08%2F20160525083516_2701.png
date:           2018-10-03 20:00:00
tags:           bigDataSimple
post-card-type: image
---

kafka也是现在各家互联网公司里非常常用的技术了，虽然现在我们组暂时没有用到，还是学习一手，记录下，以备不时之需。

## 1.本地kafka搭建
    1.安装brew
    2.安装kafka：brew install kafka
      配置文件位置：/usr/local/etc/kafka/server.properties
                  /usr/local/etc/kafka/zookeeper.propertie  
    3.启动zk:./bin/zookeeper-server-start /usr/local/etc/kafka/zookeeper.properties
    4.启动kafka:./bin/kafka-server-start /usr/local/etc/kafka/server.properties
    5.创建topic:./bin/kafka-topics --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic wykTest
    6.生产消息:./bin/kafka-console-producer.sh --broker-list localhost:9092 --topic wykTest
    7.消费消息:./bin/kafka-console-consumer --bootstrap-server localhost:9092 --topic wykTest --from-beginning
    
   ![MacDown Screenshot](/assets/images/1529222633283.jpg)
    
    
    
## 2.kafka

#### 1.kafka组件
   
    话题（Topic）：是特定类型的消息流。消息是字节的有效负载（Payload），话题是消息的分类名或种子（Feed）名。

    生产者（Producer）：是能够发布消息到话题的任何对象。

    服务代理（Broker）：已发布的消息保存在一组服务器中，它们被称为代理（Broker）或Kafka集群。

    消费者（Consumer）：可以订阅一个或多个话题，并从Broker拉数据，从而消费这些已发布的消息。
    
    
#### 2.Kafka存储

    kafka以topic来进行消息管理，每个topic包含多个partition，每个partition对应一个逻辑log，有多个segment组成。
    
    每个segment中存储多条消息（见下图），消息id由其逻辑位置决定，即从消息id可直接定位到消息的存储位置，避免id到位置的额外映射。
    
    发布者发到某个topic的消息会被均匀的分布到多个partition上（或根据用户指定的路由规则进行分布），broker收到发布消息往对应partition的最后一个segment上添加该消息，当某个segment上的消息条数达到配置值或消息发布时间超过阈值时，segment上的消息会被flush到磁盘，只有flush到磁盘上的消息订阅者才能订阅到，segment达到一定的大小后将不会再往该segment写数据，broker会创建新的segment。
    
    同一个topic下有多个不同的partition，每个partition为一个目录，partition命名的规则是topic的名称加上一个序号，序号从0开始。
    
    每一个partition目录下的文件被平均切割成大小相等（默认一个文件是500兆，可以手动去设置）的数据文件，每一个数据文件都被称为一个segment，默认保留7天的数据。
    
    
![MacDown Screenshot](/assets/images/434101-20160514145722812-631325437.png)
    
    
#### 3.segment存储策略

    segment由index和data文件组成，两个文件成对出现，分别存储索引和数据。
    
    segment文件命名规则：对于所有的partition来说，segment名称从0开始，之后的每一个segment名称为上一个segment文件最后一条消息的offset值。
    
    通过二分法查找对应offect对应的message。
    

![MacDown Screenshot](/assets/images/20180601133520643.png)
    

#### 4.kafka数据保留策略

    N天前的删除。

    保留最近的多少Size数据。
    
#### 5.kafka如何保证数据的不丢失

生产者：

ack机制：broker表示发来的数据已确认接收无误，表示数据已经保存到磁盘。

    0：不等待broker返回确认消息

    1：等待topic中某个partition leader保存成功的状态反馈

    -1：等待topic中某个partition 所有副本都保存成功的状态反馈
    
消费者：

    通过offset commit 来保证数据的不丢失，kafka自己记录了每次消费的offset数值，下次继续消费的时候，接着上次的offset进行消费即可。
   
    




参考：https://blog.csdn.net/u010046908/article/details/62229015

https://www.cnblogs.com/luxiaoxun/p/5492646.html

https://www.cnblogs.com/jun1019/p/6256514.html

https://blog.csdn.net/qq_41455420/article/details/79372696

https://blog.csdn.net/xiamaocheng/article/details/57512573