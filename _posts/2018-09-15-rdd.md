---
layout:         post
title:          spark基本原理
subtitle:       
card-image:     https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1546686802345&di=21fc854bf1d79fb49c6e8694edf31e2a&imgtype=0&src=http%3A%2F%2Fwww.raincent.com%2Fuploadfile%2F2017%2F1206%2F20171206105128367.jpg
date:           2018-09-15 21:00:00
tags:           bigDataSimple
post-card-type: image
---

## rdd

    1.RDD是Spark提供的核心抽象，即弹性分布式数据集（弹性指rdd可以权衡数据存储在内存或磁盘）

    2.RDD有分区，如一个RDD有90万数据，10个分区，每个10万数据；默认一个分区最大128M，可通过spark.files.maxPartitionBytes调节。
    
    3.每个分区都会被一个计算任务处理，并决定并行计算的粒度。用户可以在创建RDD时指定RDD的分片个数，如果没有指定，那么就会采用默认值。默认值就是程序所分配到的CPU Core的数目。
    
    4.RDD之间会形成类似于流水线一样的前后依赖关系。在部分分区数据丢失时，Spark可以通过这个依赖关系重新计算丢失的分区数据，而不是对RDD的所有分区进行重新计算（容错性很强）。
    
    5.在spark读取hdfs的场景下，spark把hdfs的block块(默认128M)读到内存就会抽象成spark的partition。对于后续的操作，遇到需要shuffle的操作RDD中的块可以按照HashPartitioner(默认）或者rangePartitioner再次进行进行划分，一般pairRdd是使用key做hash再取余（hashpartitioner）来划分partition的。
    
    6.在spark的计算末尾一般需要把数据持久化，RDD中的每个partition都会被保存成hdfs上的一个文件，如果此文件小于128M，那么相当于RDD中的一个partition对应一个hadoop的block块。如果，这个文件大于128M,那么这个文件会被切分成多个block块，这样一个spark中partition就会对应hdfs上的多个block。
    
    7.RDD通过persist方法或cache方法可以将前面的计算结果缓存，但是并不是这两个方法被调用时立即缓存，而是触发后面的action时，该RDD将会被缓存在计算节点的内存中，并供后面重用。
    
    8.RDD和它依赖的父RDD（s）的关系有两种不同的类型，即窄依赖和宽依赖。
    
    9.DAG叫做有向无环图，宽依赖是划分Stage的依据。
    
    10.







参考：https://blog.csdn.net/ap0810217/article/details/55195962

https://www.cnblogs.com/atomicbomb/p/7488278.html

https://blog.csdn.net/u010990043/article/details/77683823


