---
layout:         post
title:          大数据知识点整理
subtitle:       
card-image:     https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1540704612756&di=873baeeb81f53b5bb8d9cb246f484fae&imgtype=0&src=http%3A%2F%2Fseopic.699pic.com%2Fphoto%2F50064%2F9111.jpg_wh1200.jpg
date:           2018-10-28 10:00:00
tags:           bigDataInterview
post-card-type: image
---


### 1.Hadoop

##### 1.简述如何安装配置apache 的一个开源的hadoop

    1 ) 安装JDK并配置环境变量（/etc/profile）

    2) 关闭防火墙

    3) 配置hosts文件，方便hadoop通过主机名访问（/etc/hosts）

    4) 设置ssh免密码登录

    5) 解压缩hadoop安装包，并配置环境变量

    6) 修改配置文件（ $HADOOP_HOME/conf ）
    
    hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml
    
    包括：namenode、secondarynamenode通信地址,hdfs副本数量,mapreduce使用framework（yarn）,yarn的resourcemanager等

    7) 格式化hdfs文件系统 （hadoop namenode -format）

    8) 启动hadoop （ $HADOOP_HOME/bin/start-all.sh ）

    9) 使用jps查看进程
  
详情：https://www.linuxidc.com/Linux/2017-03/142051.htm


##### 2.列出hadoop集群中的都分别需要启动哪些进程，及其作用

    1.Namenode:维护元数据信息，当jobClient进行读写请求的时候，返回block和datanode的位置信息。

    2.SecondaryNameNode:协助namenode进行元数据的合并，一定范围内的数据备份。

    3.Datanode：存储数据，向namenode发送心跳报告，接收namenode节点的指令以及Block副本的复制

    4.ResourceManager：在yarn中，resourceManager负责集群中所有资源的统一管理和分配，接收来自各个节点的资源回报信息，并把这些信息按照一定的策略分配给各个应用程序。

    5.NodeManager：是yarn中每个节点上的代理，他管理hadoop集群中单个计算节点包括与resourcesManager保持通信，监督Container的生命周期管理，监控每个Container的资源使用情况，追踪节点健康状况，管理日志和不同应用程序用到的附属服务。

    在1.x版本中是Jobtracker：管理任务，并将任务分配给taskTracker

    Taskreacker：任务的执行方。
    
    
##### 3.简述mapreduce的运行原理


![MacDown Screenshot](/assets/images/20160529192800637.png)

     Combiner可以理解为一个小的Reduce，就是把每个Map的结果，先做一次整合;
     
     Partitioner为了保证所有的主键相同的key值对能传输给同一个Reduce节点.


##### 4.hive中内部外部表的区别

    1.未被external修饰的是内部表，被external修饰的为外部表； 

    2.内部表数据由Hive自身管理，外部表数据由HDFS管理；
     
    3.内部表数据存储的位置是hive.metastore.warehouse.dir（默认：/user/hive/warehouse）,外部表数据的存储位置由自己制定； 

    4.删除内部表会直接删除元数据（metadata）及存储数据；删除外部表仅仅会删除元数据，HDFS上的文件并不会被删除； 
    

##### 5.mapreduce中的combiner和partition的区别

    1.partition
    
    分割map每个节点的结果，按照key分别映射给不同的reduce，可以自定义;
    
    默认使用哈希函数来划分分区,HashPartitioner是mapreduce的默认partitioner。
    
    HashPartitioner计算方法是which reducer=(key.hashCode() & Integer.MAX_VALUE) % numReduceTasks，得到当前的目的reducer。
    
    当map输出的时候，写入缓存之前，会调用partition函数，计算出数据所属的分区，并且把这个元数据存储起来。
    
    当数据达到溢出的条件时，读取缓存中的数据和分区元数据，然后把属与同一分区的数据合并到一起。
    
    2.combiner
    
    计算规则与reduce一致(在map端做);
    
    combiner只应该用于那种Reduce的输入key/value与输出key/value类型完全一致，因为combine本质上就是reduce操作;
    
详细：https://blog.csdn.net/yangjjuan/article/details/78119399

##### 6.跨集群数据同步distcp的原理

##### 7.描述mapreduce的过程，中间有几次写磁盘

##### 8.ORC、Parquet等列式存储的优点

##### 9.hive倾斜原因，怎么解决，mapjoin


### 2.Spark

##### 1.RDD中reduceBykey与groupByKey的区别


### 3.Yarn


##### 1.对yarn的理解


### 4.Redis

##### 1.Redis性能优化，单机增加CPU核数是否会提高性能


### 5.kafka

##### 1.采集数据为什么选择kafka

### 6.Sqoop

##### 1.datax的架构，为什么不用sqoop


### 7.Java 

##### 1.ArraryBlockingQueue的实现

##### 2.JVM参数调优经验


### 8.ZK

##### 1.zookkeeper HA原理


### 9.数据结构及算法

##### 1.大顶堆、小顶堆；堆的建堆过程，调整过程

##### 2.排序算法

##### 3.二分法以及变种

### 10.


### N.其他

##### 1.项目中遇到什么难题，有没有数据丢失，怎么解决

##### 2.讲一讲checkpoint

##### 3.调度系统的实现，开源调度系统Azkaban



### 10.