---
layout:         post
title:          大数据知识点整理
subtitle:       
card-image:     https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1540704612756&di=873baeeb81f53b5bb8d9cb246f484fae&imgtype=0&src=http%3A%2F%2Fseopic.699pic.com%2Fphoto%2F50064%2F9111.jpg_wh1200.jpg
date:           2018-10-28 10:00:00
tags:           bigDataInterview
post-card-type: image
---


### 1.Hadoop

##### 1.简述如何安装配置apache 的一个开源的hadoop

    1 ) 安装JDK并配置环境变量（/etc/profile）

    2) 关闭防火墙

    3) 配置hosts文件，方便hadoop通过主机名访问（/etc/hosts）

    4) 设置ssh免密码登录

    5) 解压缩hadoop安装包，并配置环境变量

    6) 修改配置文件（ $HADOOP_HOME/conf ）
    
    hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml
    
    包括：namenode、secondarynamenode通信地址,hdfs副本数量,mapreduce使用framework（yarn）,yarn的resourcemanager等

    7) 格式化hdfs文件系统 （hadoop namenode -format）

    8) 启动hadoop （ $HADOOP_HOME/bin/start-all.sh ）

    9) 使用jps查看进程
  
详情：https://www.linuxidc.com/Linux/2017-03/142051.htm


##### 2.列出hadoop集群中的都分别需要启动哪些进程，及其作用

    1.Namenode:维护元数据信息，当jobClient进行读写请求的时候，返回block和datanode的位置信息。

    2.SecondaryNameNode:协助namenode进行元数据的合并，一定范围内的数据备份。

    3.Datanode：存储数据，向namenode发送心跳报告，接收namenode节点的指令以及Block副本的复制

    4.ResourceManager：在yarn中，resourceManager负责集群中所有资源的统一管理和分配，接收来自各个节点的资源回报信息，并把这些信息按照一定的策略分配给各个应用程序。

    5.NodeManager：是yarn中每个节点上的代理，他管理hadoop集群中单个计算节点包括与resourcesManager保持通信，监督Container的生命周期管理，监控每个Container的资源使用情况，追踪节点健康状况，管理日志和不同应用程序用到的附属服务。

    在1.x版本中是Jobtracker：管理任务，并将任务分配给taskTracker

    Taskreacker：任务的执行方。
    
    
##### 3.简述mapreduce的运行原理


![MacDown Screenshot](/assets/images/20160529192800637.png)

     Combiner可以理解为一个小的Reduce，就是把每个Map的结果，先做一次整合;
     
     Partitioner为了保证所有的主键相同的key值对能传输给同一个Reduce节点.


##### 4.hive中内部外部表的区别

    1.未被external修饰的是内部表，被external修饰的为外部表； 

    2.内部表数据由Hive自身管理，外部表数据由HDFS管理；
     
    3.内部表数据存储的位置是hive.metastore.warehouse.dir（默认：/user/hive/warehouse）,外部表数据的存储位置由自己制定； 

    4.删除内部表会直接删除元数据（metadata）及存储数据；删除外部表仅仅会删除元数据，HDFS上的文件并不会被删除； 
    

##### 5.mapreduce中的combiner和partition的区别

    1.partition
    
    分割map每个节点的结果，按照key分别映射给不同的reduce，可以自定义;
    
    默认使用哈希函数来划分分区,HashPartitioner是mapreduce的默认partitioner。
    
    HashPartitioner计算方法是which reducer=(key.hashCode() & Integer.MAX_VALUE) % numReduceTasks，得到当前的目的reducer。
    
    当map输出的时候，写入缓存之前，会调用partition函数，计算出数据所属的分区，并且把这个元数据存储起来。
    
    当数据达到溢出的条件时，读取缓存中的数据和分区元数据，然后把属与同一分区的数据合并到一起。
    
    2.combiner
    
    计算规则与reduce一致(在map端做);
    
    combiner只应该用于那种Reduce的输入key/value与输出key/value类型完全一致，因为combine本质上就是reduce操作;
    
详细：https://blog.csdn.net/yangjjuan/article/details/78119399

##### 6.跨集群数据同步distcp的原理

     1.hadoop distcp –m 10 hdfs://namenodeA/data/weblogs hdfs://namenodeB/data/ weblogs 
     
     2.文件夹中的内容将被复制为一个临时的大文件，这些文件内容的拷贝工作被分配给多个map任务
     
     3.将会启动一个只有map的MapReduce作业来实现两个集群间的数据复制。默认情况下，每个map就将会分配到一个256MB的数据块文件

##### 7.描述mapreduce的过程，中间有几次写磁盘
 
     1.spill:
      map过程中将Kvbuffer（Kvmeta存放索引，索引会根据partition和key排序）中的数据达到spill阈值
     （如80%）后从所有的本地目录中轮训查找能存储这么大空间的目录，创建一个类似于 “spill12.out”的文件
      Spill线程根据排过序的Kvmeta挨个把partition的数据吐到这个文件中，直到把所有的partition遍历完
      同时创建一个“spill12.out.index”文件存索引信息;这些文件很多的话会被Merge成少量文件。
     
     2.cpoy:
      Reduce任务通过HTTP向各个Map任务拖取它所需要的数据,拖一个Map数据过来就会创建一个文件;
      有些Map的数据较小放在内存中，有些Map的数据大放在磁盘上，最后会进行一个全局合并（磁盘、内存均可能）。
      
     3.reduce：
       根据reduce任务内容操作数据后落到hdfs上。
     
详情：https://blog.csdn.net/ebay/article/details/45722263
https://blog.csdn.net/mrlevo520/article/details/76781186

##### 8.ORC、Parquet等列式存储的优点

    1.查询的时候不需要扫描全部的数据，而只需要读取每次查询涉及的列，这样可以将I/O消耗降低N倍，另外可以保存每一列的统计信息(min、max、sum等)，实现部分的谓词下推。
    
    2.由于每一列的成员都是同构的，可以针对不同的数据类型使用更高效的数据压缩算法，进一步减小I/O。
    
    3.由于每一列的成员的同构性，可以使用更加适合CPU pipeline的编码方式，减小CPU的缓存失效。

详情：https://blog.csdn.net/yu616568/article/details/51868447/

##### 9.hive倾斜原因，怎么解决，mapjoin


### 2.Spark

##### 1.RDD中reduceBykey与groupByKey的区别


### 3.Yarn


##### 1.对yarn的理解


### 4.Redis

##### 1.Redis性能优化，单机增加CPU核数是否会提高性能


### 5.kafka

##### 1.采集数据为什么选择kafka

### 6.Sqoop

##### 1.datax的架构，为什么不用sqoop


### 7.Java 

##### 1.ArraryBlockingQueue的实现

##### 2.JVM参数调优经验


### 8.ZK

##### 1.zookkeeper HA原理


### 9.数据结构及算法

##### 1.大顶堆、小顶堆；堆的建堆过程，调整过程

##### 2.排序算法

##### 3.二分法以及变种

### 10.


### N.其他

##### 1.项目中遇到什么难题，有没有数据丢失，怎么解决

##### 2.讲一讲checkpoint

##### 3.调度系统的实现，开源调度系统Azkaban

