---
layout:         post
title:          大数据知识点整理
subtitle:       
card-image:     https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1540704612756&di=873baeeb81f53b5bb8d9cb246f484fae&imgtype=0&src=http%3A%2F%2Fseopic.699pic.com%2Fphoto%2F50064%2F9111.jpg_wh1200.jpg
date:           2018-10-28 10:00:00
tags:           bigDataInterview
post-card-type: image
---


### 1.Hadoop

##### 1.简述如何安装配置apache 的一个开源的hadoop

    1 ) 安装JDK并配置环境变量（/etc/profile）

    2) 关闭防火墙

    3) 配置hosts文件，方便hadoop通过主机名访问（/etc/hosts）

    4) 设置ssh免密码登录

    5) 解压缩hadoop安装包，并配置环境变量

    6) 修改配置文件（ $HADOOP_HOME/conf ）
    
    hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml
    
    包括：namenode、secondarynamenode通信地址,hdfs副本数量,mapreduce使用framework（yarn）,yarn的resourcemanager等

    7) 格式化hdfs文件系统 （hadoop namenode -format）

    8) 启动hadoop （ $HADOOP_HOME/bin/start-all.sh ）

    9) 使用jps查看进程
  
详情：https://www.linuxidc.com/Linux/2017-03/142051.htm


##### 2.列出hadoop集群中的都分别需要启动哪些进程，及其作用

    1.Namenode:维护元数据信息，当jobClient进行读写请求的时候，返回block和datanode的位置信息。

    2.SecondaryNameNode:协助namenode进行元数据的合并，一定范围内的数据备份。

    3.Datanode：存储数据，向namenode发送心跳报告，接收namenode节点的指令以及Block副本的复制

    4.ResourceManager：在yarn中，resourceManager负责集群中所有资源的统一管理和分配，接收来自各个节点的资源回报信息，并把这些信息按照一定的策略分配给各个应用程序。

    5.NodeManager：是yarn中每个节点上的代理，他管理hadoop集群中单个计算节点包括与resourcesManager保持通信，监督Container的生命周期管理，监控每个Container的资源使用情况，追踪节点健康状况，管理日志和不同应用程序用到的附属服务。

    在1.x版本中是Jobtracker：管理任务，并将任务分配给taskTracker

    Taskreacker：任务的执行方。
    
    
##### 3.简述mapreduce的运行原理


![MacDown Screenshot](/assets/images/20160529192800637.png)

     Combiner可以理解为一个小的Reduce，就是把每个Map的结果，先做一次整合;
     
     Partitioner为了保证所有的主键相同的key值对能传输给同一个Reduce节点.


##### 4.hive中内部外部表的区别

    1.未被external修饰的是内部表，被external修饰的为外部表； 

    2.内部表数据由Hive自身管理，外部表数据由HDFS管理；
     
    3.内部表数据存储的位置是hive.metastore.warehouse.dir（默认：/user/hive/warehouse）,外部表数据的存储位置由自己制定； 

    4.删除内部表会直接删除元数据（metadata）及存储数据；删除外部表仅仅会删除元数据，HDFS上的文件并不会被删除； 
    

##### 5.mapreduce中的combiner和partition的区别

    1.partition
    
    分割map每个节点的结果，按照key分别映射给不同的reduce，可以自定义;
    
    默认使用哈希函数来划分分区,HashPartitioner是mapreduce的默认partitioner。
    
    HashPartitioner计算方法是which reducer=(key.hashCode() & Integer.MAX_VALUE) % numReduceTasks，得到当前的目的reducer。
    
    当map输出的时候，写入缓存之前，会调用partition函数，计算出数据所属的分区，并且把这个元数据存储起来。
    
    当数据达到溢出的条件时，读取缓存中的数据和分区元数据，然后把属与同一分区的数据合并到一起。
    
    2.combiner
    
    计算规则与reduce一致(在map端做);
    
    combiner只应该用于那种Reduce的输入key/value与输出key/value类型完全一致，因为combine本质上就是reduce操作;
    
详细：https://blog.csdn.net/yangjjuan/article/details/78119399

##### 6.跨集群数据同步distcp的原理

     1.hadoop distcp –m 10 hdfs://namenodeA/data/weblogs hdfs://namenodeB/data/ weblogs 
     
     2.文件夹中的内容将被复制为一个临时的大文件，这些文件内容的拷贝工作被分配给多个map任务
     
     3.将会启动一个只有map的MapReduce作业来实现两个集群间的数据复制。默认情况下，每个map就将会分配到一个256MB的数据块文件

##### 7.描述mapreduce的过程，中间有几次写磁盘
 
     1.spill:
      map过程中将Kvbuffer（Kvmeta存放索引，索引会根据partition和key排序）中的数据达到spill阈值
     （如80%）后从所有的本地目录中轮训查找能存储这么大空间的目录，创建一个类似于 “spill12.out”的文件
      Spill线程根据排过序的Kvmeta挨个把partition的数据吐到这个文件中，直到把所有的partition遍历完
      同时创建一个“spill12.out.index”文件存索引信息;这些文件很多的话会被Merge成少量文件。
     
     2.cpoy:
      Reduce任务通过HTTP向各个Map任务拖取它所需要的数据,拖一个Map数据过来就会创建一个文件;
      有些Map的数据较小放在内存中，有些Map的数据大放在磁盘上，最后会进行一个全局合并（磁盘、内存均可能）。
      
     3.reduce：
       根据reduce任务内容操作数据后落到hdfs上。
     
详情：https://blog.csdn.net/ebay/article/details/45722263
https://blog.csdn.net/mrlevo520/article/details/76781186

##### 8.ORC、Parquet等列式存储的优点

    1.查询的时候不需要扫描全部的数据，而只需要读取每次查询涉及的列，这样可以将I/O消耗降低N倍，另外可以保存每一列的统计信息(min、max、sum等)，实现部分的谓词下推。
    
    2.由于每一列的成员都是同构的，可以针对不同的数据类型使用更高效的数据压缩算法，进一步减小I/O。
    
    3.由于每一列的成员的同构性，可以使用更加适合CPU pipeline的编码方式，减小CPU的缓存失效。

详情：https://blog.csdn.net/yu616568/article/details/51868447/

##### 9.hive倾斜原因，怎么解决，mapjoin

    1.map端生成的key分布不均匀
    
    2.一般join:
     读取源表的数据，Map输出时候以Join on条件中的列为key，如果Join有多个关联键，则以这些关联键的组合作为key;
     Map输出的value为join之后所关心的(select或者where中需要用到的)列；同时在value中还会包含表的Tag信息，
     用于标明此value对应哪个表；按照key进行排序
     
    3.mapjoin会把小表全部读入内存中，在map阶段直接拿另外一个表的数据和内存中表数据做匹配，而普通的
     equality join则是类似于mapreduce模型中的file join，需要先分组，然后再reduce端进行连接；
     由于mapjoin是在map是进行了join操作，省去了reduce的运行，效率也会高很多

详情：http://lxw1234.com/archives/2015/06/313.htm
https://blog.csdn.net/liuxiao723846/article/details/78739097


### 2.Spark

##### 1.RDD中reduceBykey与groupByKey的区别

    1.reduceByKey会在结果发送至reducer之前会对每个mapper在本地进行merge，有点类似于在MapReduce中的combiner。
     这样做的好处在于，在map端进行一次reduce之后，数据量会大幅度减小，从而减小传输，保证reduce端能够更快的进行结果计算。
    
    2.groupByKey会对每一个RDD中的value值进行聚合形成一个序列(Iterator)，此操作发生在reduce端，所以势必会将所有
      的数据通过网络进行传输，造成不必要的浪费。同时如果数据量十分大，可能还会造成OutOfMemoryError。

详情：https://www.cnblogs.com/0xcafedaddy/p/7625358.html


### 3.Yarn


##### 1.对yarn的理解

    1.hadoop https://www.cnblogs.com/cxzdy/p/5494929.html
    
    2.spark https://wyk2011fj.github.io/2018/07/yarn/


### 4.Redis

##### 1.Redis性能优化，单机增加CPU核数是否会提高性能

    1.单一线程也只能用到一个cpu核心，可以在同一个多核的服务器中，可以启动多个实例，
      组成master-master或者master- slave的形式，耗时的读命令可以在slave进行
     
    2.rdb(快照持久化)：Redis主进程fork出一个子进程，持久化工作由子进程完成
      Redis crash掉之后，重启时能够自动恢复到上一次RDB快照中记录的数据。
      
      优点：对性能影响最小；
           容灾；
           进行数据恢复比使用AOF要快很多。
      缺点：定点，会丢数据；
           如果cpu不够强(比如单核CPU),Redis在fork子进程时可能会消耗较长的时间(长至1秒),影响客户端请求。
           
     3.AOF:Redis会把每一个写请求都记录在一个日志文件里。
           在Redis重启时，会把AOF文件中记录的所有写操作顺序执行一遍，确保数据恢复到最新
           AOF默认是关闭的，可自行配置（随时；1秒一次；系统决定）
        
       优点：安全，数据丢失少
            断电等，日志没写全，redis-check-aof工具可修复
            AOF文件易读，可修改（错误操作时）
       
       缺点：AOF文件通常比RDB文件更大
            性能消耗比RDB高
            数据恢复速度比RDB慢
            
      4.pipelining：实现在一次交互中执行多条命令
        只需要从客户端一次向Redis发送多条命令（以\r\n）分隔，Redis会依次执行这些命令，
        并且把每个命令的返回按顺序组装在一起一次返回
        缺点：只能用于执行连续且无相关性的命令，当命令的生成依赖于前一命令的返回时，就无法使用了。

详情：https://www.cnblogs.com/276815076/p/7245333.html


### 5.kafka

##### 1.采集数据为什么选择kafka
 
    1.同时为发布和订阅提供高吞吐量(多消费者)。
     
    2.可进行持久化操作。将消息持久化到磁盘，因此可用于批量消费。
    
    3.分布式系统，易于向外扩展。
    
    4.消息被处理的状态是在consumer端维护，而不是由server端维护。当失败时能自动平衡。
    
    5.支持online和offline的场景。
    
原理：https://wyk2011fj.github.io/2018/10/Kafka/

### 6.Sqoop

##### 1.datax的架构，为什么不用sqoop

    1.


### 7.Java 

##### 1.ArraryBlockingQueue的实现

##### 2.JVM参数调优经验


### 8.ZK

##### 1.zookkeeper HA原理


### 9.数据结构及算法

##### 1.大顶堆、小顶堆；堆的建堆过程，调整过程

##### 2.排序算法

##### 3.二分法以及变种

### 10.


### N.其他

##### 1.项目中遇到什么难题
        

##### 2.讲一讲checkpoint

##### 3.调度系统的实现，开源调度系统Azkaban

##### 4.有没有数据丢失，怎么解决

