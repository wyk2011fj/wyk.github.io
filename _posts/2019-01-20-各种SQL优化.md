---
layout:         post
title:          关于SQL
subtitle:       慢慢积累一些各种sql的优化方式及技巧
card-image:     https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1547989001558&di=9de99b3910502ff78189dbcb9545ecfb&imgtype=0&src=http%3A%2F%2Fwww.onekit.cn%2Fimages%2Fsql.png
date:           2019-01-20 18:30:00
tags:           bigDataDetail
post-card-type: image
---

其实，相信目前大多数公司实际处理数据（主要是离线数据），基本都还是用sql的方式居多，大数据量下用hive sql、spark sql等，在关系型数据库中包括oracle、mysql等也是用sql处理逻辑，所以，慢慢搜集和积累一些sql优化或者问题处理的方法和技巧还是有必要的，先init一手，后续慢慢加。

## 1.Hive SQL

HQL本质上是MapReduce任务，一般map task从数据源获取数据，再经过shuffle操作到reduce端由reduce task进行操作，最终产出数据，各种花里胡哨的情况都是有可能拖慢整个任务的；

##### Map长尾

就是一些map任务读取并处理的数据特别多，一些map任务处理的数据特别少，造成map端长尾；

原因：一般是因为文件大小分布不均匀导致

解决方式：1.合并小文件，尽量让文件大小分布均匀 2.增加map数量

展开：

    1.Map数量不是单纯由用户设置的，是由InputFormat接口的getSplits方法决定；  
    每个map处理一个fileSplit，即 map数=fileSplit数；
      
    逻辑为：
    
    分片大小：splitSize = max (minSize, min(goalSize, dfs.block.size))
    
    其中：
    
    goalSize = totalSize / mapred.map.tasks
    minSize = max {mapred.min.split.size, minSplitSize}
    
    totalSize：一个JOB的所有map总的输入大小
    mapred.map.tasks：默认2，期望map数
    minSplitSize：默认为1，可复写（特殊情况）
    dfs.block.size：1.X默认64M，2.X默认128M
    
    Map数量：
    文件大小/splitSize>1.1，创建一个split，即一个map task；
    文件剩余大小/splitSize<1.1，剩余的部分作为一个split；
    
    结论：
    通过调节 mapred.map.tasks（期望map数）和 mapred.min.split.size（最小文件分割大小）
    可实际实现 map数量 的控制；
    
    实际应用：
    想增加map个数，设置 mapred.map.tasks 为一个较大的值，如map长尾问题；
    想减小map个数，设置 mapred.min.split.size 为一个较大的值，如小文件过多；
    
    2.Hive小文件合并
    
    Map-only的任务结束时合并小文件：
    sethive.merge.mapfiles = true
  
    在Map-Reduce的任务结束时合并小文件：
    sethive.merge.mapredfiles= true
  
    当输出文件的平均大小小于1GB时，启动一个独立的map-reduce任务进行文件merge：
    sethive.merge.smallfiles.avgsize=1024000000

    3.Spark小文件合并
    
    之前写过了：https://wyk2011fj.github.io/2018/11/spark-small-file/
    
##### Join长尾

SQL在Join执行阶段会将Join Key相同的数据分发到同一个执行Instance上处理。如果某个Key上的数据量比较多，会导致该Instance执行时间比其他Instance执行时间长；

1.小表长尾

当某路输入比较小，可以采用Mapjoin避免倾斜。原理是将Join操作提前到Map端执行，这样可以避免因为分发Key不均匀导致数据倾斜。

Mapjoin的使用有限制，必须是Join中的从表比较小才可用。所谓从表，即Left Outer Join中的右表，或者Right Outer Join中的左表。

展开：

    1.Common join
    
    Map阶段
    读取源表的数据，Map输出时候以Join on条件中的列为key；
    Map输出的value(含所属表信息)为join之后所关心的(select或者where中需要用到的)列；
    按照key进行排序；

    Shuffle阶段
    根据key的值进行hash,并将key/value按照hash值推送至不同的reduce中；
    （每个map都可能有所有的key）        

    Reduce阶段
    根据key的值完成join操作。
    
    2.MapJoin
    
    原理：
    把小表全部读入内存中，在map阶段直接拿另外一个表的数据和内存中表数据做匹配，即完成join操作；
    
    相关设置：
    小表自动选择Mapjoin: hive.auto.convert.join=true
    小表阈值:hive.mapjoin.smalltable.filesize (默认25M)
    (下面两个不常用)
    mapjoin做group by时可以使用的最大内存占比：
    hive.mapjoin.followby.gby.localtask.max.memory.usage （默认0.55）
    本地mapjoin可以使用内存占比：hive.mapjoin.localtask.max.memory.usage （默认0.9）
    
    
    

## 2.Oracle SQL

......
    



原文：https://www.cnblogs.com/duanxingxing/p/6874318.html
https://www.cnblogs.com/qinwangchen/p/5837940.html
https://www.cnblogs.com/1130136248wlxk/articles/5294955.html
https://www.cnblogs.com/qiuhong10/p/7698277.html
https://blog.csdn.net/kwu_ganymede/article/details/51365002
