---
layout:         post
title:          关于SQL
subtitle:       慢慢积累一些各种sql的优化方式及技巧
card-image:     https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1547989001558&di=9de99b3910502ff78189dbcb9545ecfb&imgtype=0&src=http%3A%2F%2Fwww.onekit.cn%2Fimages%2Fsql.png
date:           2019-01-20 18:30:00
tags:           bigDataDetail
post-card-type: image
---

其实，相信目前大多数公司实际处理数据（主要是离线数据），基本都还是用sql的方式居多，大数据量下用hive sql、spark sql等，在关系型数据库中包括oracle、mysql等也是用sql处理逻辑，所以，慢慢搜集和积累一些sql优化或者问题处理的方法和技巧还是有必要的，先init一手，后续慢慢加。

## 1.Hive SQL

HQL本质上是MapReduce任务，一般map task从数据源获取数据，再经过shuffle操作到reduce端由reduce task进行操作，最终产出数据，各种花里胡哨的情况都是有可能拖慢整个任务的；

##### Map长尾

就是一些map任务读取并处理的数据特别多，一些map任务处理的数据特别少，造成map端长尾；

原因：一般是因为文件大小分布不均匀导致

解决方式：1.合并小文件，尽量让文件大小分布均匀 2.增加map数量

展开：

    1.Map数量不是单纯由用户设置的，是由InputFormat接口的getSplits方法决定；  
    每个map处理一个fileSplit，即 map数=fileSplit数；
      
    逻辑为：
    
    分片大小：splitSize = max (minSize, min(goalSize, dfs.block.size))
    
    其中：
    
    goalSize = totalSize / mapred.map.tasks
    minSize = max {mapred.min.split.size, minSplitSize}
    
    totalSize：一个JOB的所有map总的输入大小
    mapred.map.tasks：默认2，期望map数
    minSplitSize：默认为1，可复写（特殊情况）
    dfs.block.size：1.X默认64M，2.X默认128M
    
    Map数量：
    文件大小/splitSize>1.1，创建一个split，即一个map task；
    文件剩余大小/splitSize<1.1，剩余的部分作为一个split；
    
    结论：
    通过调节 mapred.map.tasks（期望map数）和 mapred.min.split.size（最小文件分割大小）
    可实际实现 map数量 的控制；
    
    实际应用：
    想增加map个数，设置 mapred.map.tasks 为一个较大的值，如map长尾问题；
    想减小map个数，设置 mapred.min.split.size 为一个较大的值，如小文件过多；
    
    2.Hive小文件合并
    
    Map-only的任务结束时合并小文件：
    sethive.merge.mapfiles = true
  
    在Map-Reduce的任务结束时合并小文件：
    sethive.merge.mapredfiles= true
  
    当输出文件的平均大小小于1GB时，启动一个独立的map-reduce任务进行文件merge：
    sethive.merge.smallfiles.avgsize=1024000000

    3.Spark小文件合并
    
    写过了：[之前写过了](https://wyk2011fj.github.io/2018/11/spark%E5%B0%8F%E6%96%87%E4%BB%B6%E8%BF%87%E5%A4%9A%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/)
    
##### Join长尾


    
    



原文：https://www.cnblogs.com/duanxingxing/p/6874318.html
https://www.cnblogs.com/qinwangchen/p/5837940.html
https://www.cnblogs.com/1130136248wlxk/articles/5294955.html
